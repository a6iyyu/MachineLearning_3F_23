{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59906611",
   "metadata": {},
   "source": [
    "# **ðŸšŽ Tugas Lab 2**\n",
    "\n",
    "- Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "\n",
    "1. Menggunakan data `spam.csv`\n",
    "\n",
    "2. Fitur `CountVectorizer` dengan mengaktifkan **stop_words**\n",
    "\n",
    "3. Evaluasi hasilnya\n",
    "\n",
    "- Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "\n",
    "1. Menggunakan data `spam.csv`\n",
    "\n",
    "2. Fitur `TF-IDF` dengan mengaktifkan **stop_words**\n",
    "\n",
    "3. Evaluasi hasilnya dan bandingkan dengan hasil pada Tugas no 2.\n",
    "\n",
    "4. Berikan kesimpulan fitur mana yang terbaik pada kasus data `spam.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b730af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e26bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Pemuatan dan Persiapan Data ---\n",
    "try:\n",
    "    # Dataset spam sering menggunakan encoding 'latin-1'\n",
    "    # Kolom yang relevan adalah v1 (label) dan v2 (teks)\n",
    "    df = pd.read_csv('spam.csv', encoding='latin-1', usecols=['v1', 'v2'])\n",
    "    df.columns = ['label', 'message'] # Ganti nama kolom agar lebih jelas\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File 'spam.csv' tidak ditemukan.\")\n",
    "    print(\"Pastikan file tersebut berada di direktori yang sama dengan skrip ini.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membaca file: {e}\")\n",
    "    print(\"Mungkin ada masalah dengan encoding atau format file.\")\n",
    "    exit()\n",
    "\n",
    "print(\"--- Informasi Data Awal ---\")\n",
    "print(df.info())\n",
    "print(\"\\nContoh Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd341d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi label 'ham'/'spam' menjadi numerik (0/1)\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "# le.classes_ akan menunjukkan ['ham', 'spam'], artinya ham=0, spam=1\n",
    "\n",
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df['message']\n",
    "y = df['label_encoded']\n",
    "\n",
    "# Bagi data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nData dibagi menjadi {len(X_train)} data latih dan {len(X_test)} data tes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9dd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TUGAS 1: Multinomial Naive Bayes dengan CountVectorizer ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" TUGAS 1: Model Naive Bayes + CountVectorizer\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Inisialisasi CountVectorizer dengan stop_words='english'\n",
    "print(\"Membuat fitur menggunakan CountVectorizer (stop_words='english')...\")\n",
    "vectorizer_count = CountVectorizer(stop_words='english')\n",
    "\n",
    "# 2. Fit dan transform data latih\n",
    "X_train_count = vectorizer_count.fit_transform(X_train)\n",
    "\n",
    "# 3. Transform data tes\n",
    "X_test_count = vectorizer_count.transform(X_test)\n",
    "\n",
    "# 4. Latih model Multinomial Naive Bayes\n",
    "print(\"Melatih model MultinomialNB...\")\n",
    "model_count = MultinomialNB()\n",
    "model_count.fit(X_train_count, y_train)\n",
    "\n",
    "# 5. Prediksi data tes\n",
    "y_pred_count = model_count.predict(X_test_count)\n",
    "\n",
    "# 6. Evaluasi hasil\n",
    "acc_count = accuracy_score(y_test, y_pred_count)\n",
    "print(f\"\\nAkurasi (CountVectorizer): {acc_count:.4f}\")\n",
    "print(\"\\nLaporan Klasifikasi (CountVectorizer):\")\n",
    "# target_names=['ham', 'spam'] didapat dari le.classes_\n",
    "print(classification_report(y_test, y_pred_count, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c95d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TUGAS 2: Multinomial Naive Bayes dengan TF-IDF ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" TUGAS 2: Model Naive Bayes + TF-IDF Vectorizer\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Inisialisasi TfidfVectorizer dengan stop_words='english'\n",
    "print(\"Membuat fitur menggunakan TfidfVectorizer (stop_words='english')...\")\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# 2. Fit dan transform data latih\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "\n",
    "# 3. Transform data tes\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "# 4. Latih model Multinomial Naive Bayes\n",
    "print(\"Melatih model MultinomialNB...\")\n",
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5. Prediksi data tes\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# 6. Evaluasi hasil\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"\\nAkurasi (TF-IDF): {acc_tfidf:.4f}\")\n",
    "print(\"\\nLaporan Klasifikasi (TF-IDF):\")\n",
    "# target_names=['ham', 'spam'] didapat dari le.classes_\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TUGAS 3 & 4: Perbandingan dan Kesimpulan ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" TUGAS 3 & 4: Perbandingan dan Kesimpulan\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Akurasi Model dengan CountVectorizer: {acc_count:.4f}\")\n",
    "print(f\"Akurasi Model dengan TF-IDF Vectorizer: {acc_tfidf:.4f}\")\n",
    "\n",
    "print(\"\\n--- Kesimpulan ---\")\n",
    "if acc_tfidf > acc_count:\n",
    "    print(\"Fitur TF-IDF Vectorizer memberikan hasil akurasi yang LEBIH BAIK.\")\n",
    "    print(\"Alasan: TF-IDF tidak hanya menghitung frekuensi kata (seperti CountVectorizer),\")\n",
    "    print(\"tetapi juga memberi bobot pada kata-kata tersebut berdasarkan seberapa penting\")\n",
    "    print(\"kata itu dalam satu dokumen dan di seluruh kumpulan data.\")\n",
    "    print(\"Kata-kata yang sering muncul di semua dokumen (seperti 'call' atau 'text')\")\n",
    "    print(\"akan diberi bobot lebih rendah, sehingga model dapat fokus pada\")\n",
    "    print(\"kata-kata yang lebih unik dan informatif untuk 'spam' (misalnya 'free', 'win', 'prize').\")\n",
    "elif acc_count > acc_tfidf:\n",
    "    print(\"Fitur CountVectorizer memberikan hasil akurasi yang LEBIH BAIK.\")\n",
    "    print(\"Alasan: Ini jarang terjadi, tetapi mungkin untuk Multinomial Naive Bayes,\")\n",
    "    print(\"informasi frekuensi kata murni (raw counts) sudah cukup untuk\")\n",
    "    print(\"membedakan 'ham' dan 'spam' secara efektif pada dataset ini.\")\n",
    "    print(\"Model MNB secara inheren bekerja baik dengan hitungan (counts).\")\n",
    "else:\n",
    "    print(\"Kedua fitur (CountVectorizer dan TF-IDF) memberikan hasil akurasi yang SAMA.\")\n",
    "    print(\"Ini menunjukkan bahwa untuk dataset ini, pembobotan TF-IDF tidak memberikan\")\n",
    "    print(\"keuntungan signifikan dibandingkan frekuensi kata murni.\")\n",
    "\n",
    "print(\"\\nPada kebanyakan kasus klasifikasi teks, TF-IDF seringkali (walaupun tidak selalu)\")\n",
    "print(\"memberikan performa yang sedikit lebih unggul atau sebanding dengan CountVectorizer.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
